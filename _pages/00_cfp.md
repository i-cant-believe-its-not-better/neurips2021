---
layout: home
permalink: /
title:
desc_title: I (Still) Can't Believe It's Not Better! Workshop
description: ICBINB@NeurIPS 2021 - A Workshop for "beautiful" ideas that *should* have worked
---

### Call for Papers

Beautiful ideas have shaped scientific progress throughout history.[^1] As Paul Dirac said, “If one is working from the point of view of getting beauty in one's equations, (…), one is on a sure line of progress.[^2]” However, beautiful ideas are often overlooked in a research environment that heavily emphasizes state-of-the-art (SOTA) results, where the worth of scientific works is defined by their immediate utility and quantitative superiority instead of their creativity, diversity, and elegance. One example in machine learning is neural networks—a beautiful idea (stacked perceptron units) that did not outperform baselines initially but whose potential was still to be discovered[^3], eventually giving rise to the field of deep learning.

This workshop will explore gaps between the form and function (or, the intrinsic and extrinsic value) of ideas in ML and AI research. Some questions we will ask: Why do we find certain ideas “beautiful” (form) even when they don’t yet seem to “work” (function)? What is the value of such beautiful ideas? Does reliance on standardized evaluation or current incentives in publishing suppress beautiful ideas?

“Beauty” is of course subjective, but all researchers share the experience of valuing an idea intrinsically despite it lacking demonstrated extrinsic value.[^4] We will explore that disconnect by asking researchers to submit their “beautiful” ideas that don’t (yet) “work”. We will ask them to explain why their idea has intrinsic value, and hypothesize why it hasn’t (yet) shown its extrinsic value. In doing so, we will create a space for researchers to help each other get their “beautiful” ideas “working”.

Tensions between intrinsic and extrinsic value arise in multiple sub-fields, e.g.:
    (i) probabilistic modeling: a model’s parsimony versus its predictive performance
    (ii) deep learning: simple modular ideas easier to incorporate into different architectures versus more complicated schemes yielding higher performance
    (iii) differential privacy and algorithmic fairness: an algorithm’s mathematical elegance versus its downstream impact on sociotechnical system
    (iv) econometrics or causal inference: simple and theoretically appealing estimators vs complex estimators with more statistical efficiency

We invite submissions from these sub-fields among others in the broader ML community. Works in progress are encouraged. Submissions may touch one or more of the following aspects:
* Unexpected negative results or anomalies[^1]: ideas that do not provide expected results, yet authors are able to explain why, bringing an interesting closed-form piece of knowledge to the community
* Papers that are “stuck” yet contain beautiful/elegant ideas. Authors should argue why the idea is of interest, rigorously describe the analysis, and include a self-critique
* Criticism of and alternatives to current evaluation metrics and default practices
* Meta-research on the role of “beauty” or negative results in ML research



### Speakers

<table style="width:100%;border-bottom: 1px solid black;">
  <tr>
    <td style="text-align:center"><img src="https://cocosci.princeton.edu/tom/griffiths_0_0.jpg" height="175"></td>
    <td style="text-align:center"><img src="https://avatars.githubusercontent.com/u/2264591?v=4" height="175"></td>
    <td style="text-align:center"><img src="https://assets.pubpub.org/ecmq36io/51583152278875.jpg" height="175"></td>

  </tr>
  <tr>
   <td style="text-align:center"><a href="https://cocosci.princeton.edu/tom/index.php">Tom Griffiths</a> <br> Columbia</td>
   <td style="text-align:center"><a href="http://elarosca.net/">Michaela Rosca</a> <br>DeepMind</td>
   <td style="text-align:center"><a href="https://uni-tuebingen.de/en/research/core-research/cluster-of-excellence-machine-learning/research/research/cluster-research-groups/professorships/foundations-of-machine-learning-systems/">Robert Williamson</a> <br> Tübingen </td>

  </tr>
  <tr>
  <td style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Cosma_Shalizi_2.jpg/275px-Cosma_Shalizi_2.jpg" height="175"></td>
    <td style="text-align:center"><img src="http://eliassi.org/tina2017.png" height="175"></td>
    <td style="text-align:center"><img src="https://dsideweb.github.io/images/nyalleng-moorosi.jpg" height="175"></td>
  </tr>
  <tr>

   <td style="text-align:center"><a href="http://www.stat.cmu.edu/~cshalizi/http://www.stat.cmu.edu/~cshalizi/">Cosma Shalizi</a> <br> CMU (pending)</td>
   <td style="text-align:center"><a href="http://eliassi.org/">Tina Eliassi-Rad</a> <br> Northeastern </td>
   <td style="text-align:center"><a href="https://appliedmldays.org/all-time-speakers/nyalleng-moorosi">Nyalleng Moorosi</a> <br> Google AI (pending)</td>
  </tr>
</table>


### How do I submit?

We accept submissions through our [OpenReview workshop site](https://openreview.net/group?id=NeurIPS.cc/2021/Workshop/ICBINB).


Main deadline: **September 17th 23:59 Anywhere on Earth. Accept/reject notification will be sent out by September 31st.**

Check out our [submission guidelines](https://i-cant-believe-its-not-better.github.io/neurips2021/guidelines/) for more details.

### Organizers

* [Aaron Schein](http://www.columbia.edu/~as5530/), Columbia University
* [Jessica Zosa Forde](https://jzf2101.github.io/), Brown University
* [Stephanie Hyland](https://www.microsoft.com/en-us/research/people/sthyland/), Microsoft Research
* [Francisco Ruiz](https://franrruiz.github.io/), DeepMind
* [Melanie F. Pradier](https://melaniefp.github.io/), Microsoft Research

### Advisory Board

* [Tamara Broderick](https://people.csail.mit.edu/tbroderick/), Massachusetts Institute of Technology
* [Robert Williamson](https://uni-tuebingen.de/en/research/core-research/cluster-of-excellence-machine-learning/research/research/cluster-research-groups/professorships/foundations-of-machine-learning-systems/), University of Tübingen
* [Max Welling](https://staff.fnwi.uva.nl/m.welling/), University of Amsterdam

### Senior Advisory Board

* [Finale Doshi-Velez](https://finale.seas.harvard.edu/), Harvard University
* [Isabel Valera](https://ivaleram.github.io/), MPI for Intelligent System
* [David Blei](http://www.cs.columbia.edu/~blei/), Columbia University
* [Hanna Wallach](http://dirichlet.net/), Microsoft Research

### Contact

For any question or suggestion, please contact us at: <cant.believe.it.is.not.better@gmail.com>

### About

This workshop builds upon the [NeurIPS 2020 “I Can’t Believe It’s Not Better!” (ICBINB)](https://i-cant-believe-its-not-better.github.io/neurips2020/) workshop, which was motivated by the same principles but focused on unexpected negative results in probabilistic ML. In this call, we further unpack the concept of beauty that emerged in the discussions from the 2020 workshop. We also expand the scope to a broader ML community.

### References

[^1]: Kuhn, Thomas S. “The Structure of Scientific Revolutions.” (1962)
[^2]: Dirac PAM. The Evolution of the Physicist’s Picture of Nature. Sci Am. 1963;208: 45.
[^3]: LeCun and Hinton mention how their papers (and their colleagues’) were routinely rejected from being published based on their subject: https://youtu.be/vShMxxqtDDs?t=6m59s
[^4]: Engler, Gideon. "Aesthetics in science and in art." The British Journal of Aesthetics 30 (1990): 24-34.
